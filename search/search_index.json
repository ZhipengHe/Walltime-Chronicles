{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"A PBS Survival Guide","text":"<p>A guide nobody asked for, but everyone eventually needs.</p> <p>Welcome to Walltime Chronicles \u2014 a personal documentation project capturing all the weird, confusing, and occasionally infuriating challenges I have faced while using QUT's HPC systems (powered by PBS).</p> <p>If you have ever:</p> <ul> <li>Submitted a job that instantly failed for reasons only known to the cluster gods,</li> <li>Fought with <code>walltime</code> limits like you were disarming a bomb,</li> <li>Wondered why your script runs perfectly except when submitted through <code>qsub</code>,</li> <li>Or simply stared into the abyss of PBS logs...</li> </ul> <p>Then this is the right place.</p>"},{"location":"#what-youll-find-here","title":"What You'll Find Here","text":"<ul> <li> <p> Mystery Errors &amp; How I Solved Them   Real issues with real fixes (and real frustration).</p> </li> <li> <p> Tips, Workarounds, and Gotchas   Things that should have been in the official docs.</p> </li> <li> <p> PBS Scripts &amp; Snippets   Copy-paste-friendly templates with helpful comments.</p> </li> <li> <p> Experiments &amp; Mistakes   Because learning is messy.</p> </li> </ul>"},{"location":"#what-youll-not-find-here","title":"What You'll Not Find Here","text":"<ul> <li> <p> Basic Linux Tutorials   This isn't \"Linux for Dummies\". I assume you know your <code>ls</code> from your <code>rm -rf</code>.</p> </li> <li> <p> PBS 101   No \"What is PBS?\" here. If you don't know what <code>qsub</code> means, start with the official docs.</p> </li> <li> <p> Comprehensive Tutorials   This is a collection of \"Oh, that's why it failed!\" moments, not a step-by-step guide to HPC mastery.</p> </li> <li> <p> System Administration   I'm not your sysadmin. If you need to configure the cluster, that's above my pay grade.</p> </li> <li> <p> Debugging Your Code   Your Python script is throwing errors? That's between you and your debugger. I'm here for PBS-related mysteries only.</p> </li> <li> <p> Performance Optimisation   Want to make your code run faster? I'll share some tricks that might work, but no promises. This isn't a magic wand for your algorithms, just some PBS-specific tweaks that occasionally make things less slow.</p> </li> </ul>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>Before you start</p> <p>Before you start using this guide, please read the QUT HPC \"Aqua\" Official Documentation<sup>1</sup> and Altair's PBS Pro Documentation thoroughly.</p> <p>This is not an official QUT HPC \"Aqua\" guide. It is just my (occasionally ranty) collection of notes, meant to help others avoid the black holes I fell into. Use at your own risk \u2014 and sanity.</p> <p>Happy queueing, and may your jobs always run on the first try.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>If you have any suggestions or corrections, please feel free to open an issue or a pull request on GitHub.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. See the LICENSE file for details.</p> <ol> <li> <p>Access only in QUT network. Please use VPN to access the documentation when off-campus.\u00a0\u21a9</p> </li> </ol>"},{"location":"LICENSE/","title":"License","text":"<p>MIT License</p> <p>Copyright (c) 2025 Zhipeng He</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/","title":"Batch-Cooking PBS Scripts with a Bash Pan","text":""},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#whats-cooking","title":"What's Cooking?","text":"<p>So, you have multiple experiments, each with their own little quirks, and you want to run them one after another on the HPC without babysitting each one? Welcome to batch-cooking PBS jobs \u2014 where bash scripts are your pan, and experiments are the ingredients.</p> <p>This script is basically a recipe that:</p> <ul> <li>Grabs a timestamp so your job names never clash (like naming your children but with less emotional weight).</li> <li>Prepares a fresh PBS submission script (like meal-prepping but for compute time).</li> <li>Sets up your environment (modules + virtualenv, the usual kitchen hygiene).</li> <li>Dumps in your experiments, one by one, and gives them a nice little echo wrapper so you can read the logs without crying.</li> <li>Submits it all in one go with <code>qsub</code>.</li> </ul> <p>Result: one tidy <code>.pbs</code> file, logs clearly marked, and no waking up at 2 a.m. wondering if you ran <code>Example_Experiment_1.sh</code> twice.</p>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#how-to-customise","title":"How To Customise","text":"<p>Want to make it your own? Let's break down each part of the recipe:</p>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#1-selecting-your-ingredients-experiments","title":"1. Selecting Your Ingredients (Experiments)","text":"<p>Add or remove experiment scripts in the <code>EXPERIMENTS=(...)</code> array. This is your tasting menu \u2014 change it freely.</p> <pre><code>#!/bin/bash\n\n# List of experiments to run\n# Add or remove experiments by modifying this array\nEXPERIMENTS=(\n    \"exp_script/Example_Experiment_0.sh\"\n    \"exp_script/Example_Experiment_1.sh\"\n    \"exp_script/Example_Experiment_2.sh\"\n    # \"exp_script/My_New_Experiment.sh\"  # Uncomment to add new experiments\n    # \"path/to/another/experiment.sh\"\n)\n</code></pre>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#2-setting-up-unique-job-names","title":"2. Setting Up Unique Job Names","text":"<p>Creating a timestamp ensures your job names never clash (like naming your children but with less emotional weight).</p> <pre><code># Create a unique timestamp once\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nJOB_NAME=\"task_${TIMESTAMP}\"\nPBS_SCRIPT=\"submit_job_${TIMESTAMP}.pbs\"\n</code></pre> <p>You can customize the format:</p> <ul> <li>Change <code>task_</code> to something meaningful like <code>training_</code> or <code>analysis_</code></li> <li>Modify the timestamp format by changing <code>%Y%m%d_%H%M%S</code></li> </ul>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#3-crafting-your-pbs-header","title":"3. Crafting Your PBS Header","text":"<p>Adjust the PBS directives (walltime, resources, queue) to match your appetite and quota.</p> <pre><code># Create PBS script\ncat &gt; ${PBS_SCRIPT} &lt;&lt; EOF\n#!/bin/bash\n#PBS -N ${JOB_NAME}\n#PBS -l select=1:ncpus=8:ngpus=1:mem=64GB:gpu_id=H100  # Adjust resources here\n#PBS -M $USER@qut.edu.au  # Your email for notifications\n#PBS -l walltime=48:00:00  # Maximum runtime - format is HH:MM:SS\n#PBS -q gpuq  # Queue to submit to - adjust based on your HPC\n#PBS -j oe  # Join output and error files\n#PBS -m abe  # Mail on abort, begin, and end\n#PBS -o ${JOB_NAME}_output.log  # Output log filename\n#PBS -e ${JOB_NAME}_error.log  # Error log filename\nEOF\n</code></pre> <p>Common modifications:</p> <ul> <li>Change <code>select=1:ncpus=8:ngpus=1:mem=64GB:gpu_id=H100</code> for different resource needs</li> <li>Adjust <code>walltime=48:00:00</code> for jobs that need more or less time</li> <li>Change <code>gpuq</code> to another queue if needed (e.g., <code>cpuq</code>, <code>bigmem</code>, etc.)</li> </ul>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#4-setting-up-your-environment","title":"4. Setting Up Your Environment","text":"<p>Configure the paths and modules for your kitchen:</p> <pre><code># Add environment setup to the PBS script\ncat &gt;&gt; ${PBS_SCRIPT} &lt;&lt; EOF\n# Set paths\nWORK_DIR=\\${PBS_O_WORKDIR}\nDATASET_DIR=\\${WORK_DIR}/dataset  # Adjust dataset path if needed\n\ncd \\${PBS_O_WORKDIR}\n\n# Load required modules - customize these based on your needs\nmodule load GCCcore/13.3.0\nmodule load Python/3.12.3\nmodule load libffi/3.4.5\nmodule load CUDA/11.8.0  # Change version based on your GPU requirements\n\n# Create and activate virtual environment\npython -m venv env\nsource env/bin/activate\npython -m pip install -r requirements.txt  # Make sure this file exists!\n\n# Run experiments\ncd \\${WORK_DIR}\nEOF\n</code></pre> <p>You can modify this to:</p> <ul> <li>Change the path prefix (<code>\\${WORK_DIR}/scripts/</code>) if your scripts are stored elsewhere</li> <li>Add experiment-specific parameters</li> <li>Add timing information by adding commands like:   <pre><code>echo \"echo 'Start time: $(date)'\" &gt;&gt; ${PBS_SCRIPT}\n# ... experiment command ...\necho \"echo 'End time: $(date)'\" &gt;&gt; ${PBS_SCRIPT}\n</code></pre></li> </ul>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#5-adding-experiment-loops","title":"5. Adding Experiment Loops","text":"<p>This part adds each experiment to the PBS script with nice formatting:</p> <pre><code># Add each experiment to the PBS script\nfor exp in \"${EXPERIMENTS[@]}\"; do\n    # Add a section header for each experiment\n    echo \"echo '=============================================='\" &gt;&gt; ${PBS_SCRIPT}\n    echo \"echo 'Running experiment: ${exp}'\" &gt;&gt; ${PBS_SCRIPT}\n    echo \"echo '=============================================='\" &gt;&gt; ${PBS_SCRIPT}\n\n    # Add the experiment command (run directly)\n    echo \"bash \\${WORK_DIR}/scripts/${exp}\" &gt;&gt; ${PBS_SCRIPT}\n\n    # Add a separator between experiments\n    echo \"echo ''\" &gt;&gt; ${PBS_SCRIPT}\n    echo \"echo '=============================================='\" &gt;&gt; ${PBS_SCRIPT}\n    echo \"echo ''\" &gt;&gt; ${PBS_SCRIPT}\ndone\n</code></pre>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#6-finalizing-and-submitting","title":"6. Finalizing and Submitting","text":"<p>Make the script executable and submit it:</p> <pre><code># Make the PBS script executable\nchmod +x ${PBS_SCRIPT}\n\n# Submit the job\nqsub ${PBS_SCRIPT}\n\n# Provide helpful feedback to the user\necho \"Job submitted with name: ${JOB_NAME}\"\necho \"You can monitor the job using: qstat -u \\$USER\"\necho \"Output will be saved in: ${JOB_NAME}_output.log\"\n</code></pre> <p>You can add additional commands here to: - Copy the PBS script to an archive location - Add the job ID to a tracking file - Set up monitoring or notifications</p>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#the-complete-recipe","title":"The Complete Recipe","text":"<p>Here's the full script that you can copy, paste, and modify to suit your needs:</p> <pre><code>#!/bin/bash\n\n# Author: Zhipeng He\n# Email: zhipeng.he@hdr.qut.edu.au\n\n# List of experiments to run\n# Add or remove experiments by modifying this array\nEXPERIMENTS=(\n    \"exp_script/Example_Experiment_0.sh\"\n    \"exp_script/Example_Experiment_1.sh\"\n    \"exp_script/Example_Experiment_2.sh\"\n)\n\n# Create a unique timestamp once\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nJOB_NAME=\"task_${TIMESTAMP}\"\nPBS_SCRIPT=\"submit_job_${TIMESTAMP}.pbs\"\n\n# Create PBS script\ncat &gt; ${PBS_SCRIPT} &lt;&lt; EOF\n#!/bin/bash\n#PBS -N ${JOB_NAME}\n#PBS -l select=1:ncpus=8:ngpus=1:mem=64GB:gpu_id=H100\n#PBS -M $USER@qut.edu.au\n#PBS -l walltime=48:00:00\n#PBS -q gpuq\n#PBS -j oe\n#PBS -m abe\n#PBS -o ${JOB_NAME}_output.log\n#PBS -e ${JOB_NAME}_error.log\n# Set paths\nWORK_DIR=\\${PBS_O_WORKDIR}\nDATASET_DIR=\\${WORK_DIR}/dataset\n\ncd \\${PBS_O_WORKDIR}\n\nmodule load GCCcore/13.3.0\nmodule load Python/3.12.3\nmodule load libffi/3.4.5\nmodule load CUDA/11.8.0\n\npython -m venv env\nsource env/bin/activate\npython -m pip install -r requirements.txt\n\n# Run experiments\ncd \\${WORK_DIR}\nEOF\n\n# Add each experiment to the PBS script\nfor exp in \"${EXPERIMENTS[@]}\"; do\n    # Add a section header for each experiment\n    echo \"echo '=============================================='\" &gt;&gt; ${PBS_SCRIPT}\n    echo \"echo 'Running experiment: ${exp}'\" &gt;&gt; ${PBS_SCRIPT}\n    echo \"echo '=============================================='\" &gt;&gt; ${PBS_SCRIPT}\n\n    # Add the experiment command (run directly)\n    echo \"bash \\${WORK_DIR}/scripts/${exp}\" &gt;&gt; ${PBS_SCRIPT}\n\n    # Add a separator between experiments\n    echo \"echo ''\" &gt;&gt; ${PBS_SCRIPT}\n    echo \"echo '=============================================='\" &gt;&gt; ${PBS_SCRIPT}\n    echo \"echo ''\" &gt;&gt; ${PBS_SCRIPT}\ndone\n\n# Make the PBS script executable\nchmod +x ${PBS_SCRIPT}\n\n# Submit the job\nqsub ${PBS_SCRIPT}\n\necho \"Job submitted with name: ${JOB_NAME}\"\necho \"You can monitor the job using: qstat -u \\$USER\"\necho \"Output will be saved in: ${JOB_NAME}_output.log\" \n</code></pre>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#tips-from-the-bash-kitchen","title":"Tips from the Bash Kitchen","text":"<ul> <li>Use descriptive experiment script names \u2014 \u201cexp1.sh\u201d and \u201cexp2.sh\u201d are fine, but \"exp_doomed_to_fail.sh\" will save you time.</li> <li>Want to run things in parallel instead of sequentially? That's another recipe... and it involves GNU <code>parallel</code>, job arrays, and possibly a small ritual.</li> <li>Always <code>echo</code> your steps. Your future self, trying to debug at midnight, will thank you.</li> <li>Mind your dollar signs in heredocs! Escape PBS variables like <code>\\${PBS_O_WORKDIR}</code> but leave <code>${TIMESTAMP}</code> naked. The difference? One's for the future, one's for right now \u2014 like prepping tomorrow's lunch vs. tonight's dinner.</li> </ul>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<p>Even the best chefs have kitchen mishaps. Here's how to handle common issues:</p> <ul> <li> <p>Path Problems: If your experiments aren't running, check that the paths in the <code>EXPERIMENTS</code> array match your actual directory structure.</p> </li> <li> <p>Script Permissions: Ensure your individual experiment scripts have execute permissions:   <pre><code>chmod +x scripts/exp_script/Example_Experiment_*.sh\n</code></pre></p> </li> <li> <p>Dependency Hell: If your experiments have different Python package requirements, consider:</p> <ul> <li>Using separate virtual environments for each experiment</li> <li>Creating a unified <code>requirements.txt</code> with all dependencies</li> <li>Adding <code>pip install -r specific_requirements.txt</code> in each experiment script</li> </ul> </li> <li> <p>Resource Conflicts: If your experiments need different amounts of resources, consider making separate submission scripts rather than running them sequentially.</p> </li> </ul>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#environment-variables","title":"Environment Variables","text":"<p>Your experiment scripts can access these PBS environment variables:</p> <ul> <li><code>$PBS_O_WORKDIR</code>: The directory from which the job was submitted</li> <li><code>$PBS_JOBID</code>: The job's unique identifier</li> <li><code>$PBS_JOBNAME</code>: The name of the job (in this case, <code>task_TIMESTAMP</code>)</li> <li><code>$PBS_NODEFILE</code>: A file containing the nodes assigned to the job</li> <li><code>$PBS_QUEUE</code>: The queue the job was submitted to</li> </ul>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#advanced-techniques","title":"Advanced Techniques","text":"<p>Ready to level up your cooking skills?</p>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#handling-failures-gracefully","title":"Handling Failures Gracefully","text":"<p>To prevent later experiments from failing if an earlier one crashes:</p> <pre><code># Add to each experiment loop iteration\necho \"if bash \\${WORK_DIR}/scripts/${exp}; then\" &gt;&gt; ${PBS_SCRIPT}\necho \"  echo 'Experiment ${exp} completed successfully'\" &gt;&gt; ${PBS_SCRIPT}\necho \"else\" &gt;&gt; ${PBS_SCRIPT}\necho \"  echo 'WARNING: Experiment ${exp} failed with exit code $?'\" &gt;&gt; ${PBS_SCRIPT}\necho \"  # Continue anyway\" &gt;&gt; ${PBS_SCRIPT}\necho \"fi\" &gt;&gt; ${PBS_SCRIPT}\n</code></pre>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#experiment-status-tracking","title":"Experiment Status Tracking","text":"<p>Create a summary of completed experiments at the end:</p> <pre><code># Add before the experiments loop\necho \"declare -A experiment_status\" &gt;&gt; ${PBS_SCRIPT}\n\n# Add within the loop (replacing the direct bash command)\necho \"if bash \\${WORK_DIR}/scripts/${exp}; then\" &gt;&gt; ${PBS_SCRIPT}\necho \"  experiment_status[\\\"${exp}\\\"]=\\\"SUCCESS\\\"\" &gt;&gt; ${PBS_SCRIPT}\necho \"else\" &gt;&gt; ${PBS_SCRIPT}\necho \"  experiment_status[\\\"${exp}\\\"]=\\\"FAILED\\\"\" &gt;&gt; ${PBS_SCRIPT}\necho \"fi\" &gt;&gt; ${PBS_SCRIPT}\n\n# Add after the experiments loop\necho \"echo '============== EXPERIMENT SUMMARY ==============='\" &gt;&gt; ${PBS_SCRIPT}\necho \"for exp in \\\"${EXPERIMENTS[@]}\\\"; do\" &gt;&gt; ${PBS_SCRIPT}\necho \"  echo \\\"\\$exp: \\${experiment_status[\\\"\\$exp\\\"]}\\\"\" &gt;&gt; ${PBS_SCRIPT}\necho \"done\" &gt;&gt; ${PBS_SCRIPT}\necho \"echo '================================================'\" &gt;&gt; ${PBS_SCRIPT}\n</code></pre>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#email-notifications-with-results","title":"Email Notifications with Results","text":"<p>Add result summaries to your email notifications:</p> <pre><code># Add at the end of the script (before submission)\necho \"mail -s \\\"Job ${JOB_NAME} Complete\\\" $USER@qut.edu.au &lt; ${JOB_NAME}_output.log\" &gt;&gt; ${PBS_SCRIPT}\n</code></pre>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#happy-cooking","title":"Happy Cooking!","text":"<p>With this script, you can set up a batch of experiments, hit submit, and let the HPC do its thing while you focus on more interesting work\u2014or maybe even go outside for a change.</p> <p>Remember: A watched pot never boils, and a watched HPC job doesn't finish any faster.</p>"},{"location":"pbs-scripts/Batch-Cooking-PBS-Scripts-with-a-Bash-Pan/#coming-soon","title":"Coming Soon...","text":"<ul> <li>A version that uses PBS job arrays (aka \"batch-cooking with timers\").</li> <li>Error catching and handling \u2014 building on our \"Handling Failures Gracefully\" section.</li> <li>Log file management like a pro (or at least, like someone who doesn't grep 10GB files manually).</li> <li>Experiment templating \u2014 for when you need to run the same experiment with different flavors (parameters).</li> <li>Resource optimisation \u2014 making sure you're not using a sledgehammer to crack a nut.</li> </ul>"},{"location":"pbs-scripts/PBS-Brew-Inspector/","title":"PBS Brew Inspector: Tasting Notes from Your Job History","text":"<p>See full recipe of <code>pbs_brew_inspector.sh</code> at the end of this page.</p>"},{"location":"pbs-scripts/PBS-Brew-Inspector/#whats-in-your-computational-brew","title":"What's in Your Computational Brew?","text":"<p>Ever wondered what's really happening with those jobs you've been running? <code>pbs_brew_inspector.sh</code> is your personal sommelier for PBS jobs - swirling, sniffing, and analysing the complex flavours of your computational brews. This script extracts the subtle notes of resource usage and efficiency from your completed jobs, helping you perfect your next batch. Think of it as your lab notebook for computational experiments - documenting exactly how your recipes performed, what ingredients they consumed, and how efficient they were.</p>"},{"location":"pbs-scripts/PBS-Brew-Inspector/#the-tasting-menu","title":"The Tasting Menu","text":"<p>Running <code>pbs_brew_inspector.sh</code> produces a comprehensive report that breaks down your job history into these essential flavour components:</p> <ul> <li>Walltime Profile: How long your jobs ran versus how long you requested?</li> <li>CPU Intensity: Single-note or complex multi-core symphonies?</li> <li>Memory Usage: Light and crisp or rich and heavy?</li> <li>GPU Utilisation: The spicy kick of accelerated computing.</li> <li>Efficiency Metrics: The perfect balance of resource requests.</li> </ul>"},{"location":"pbs-scripts/PBS-Brew-Inspector/#brewing-instructions","title":"Brewing Instructions","text":"<p>Getting your tasting notes is simple. Just run the script with the appropriate flavour filters:</p> <pre><code>bash ./pbs_brew_inspector.sh -g     # Sample only GPU jobs\nbash ./pbs_brew_inspector.sh -c     # Focus on CPU-only jobs\nbash ./pbs_brew_inspector.sh -b     # Examine batch processing jobs\nbash ./pbs_brew_inspector.sh -gi    # Look at interactive GPU sessions\n</code></pre> <p>You'll be presented with a beautifully formatted table showing each job's characteristics:</p> <pre><code>&gt; bash ./pbs_brew_inspector.sh -gb # Example output for GPU batch jobs\n\nResource Usage Report -- $USER @ Wed May 14 02:47:54 PM AEST 2025\n================================================================================================================================================================\nJobID        Wall_Time   Wall_Limit  CPU_Time    CPU%        Mem(GB)    Mem_Limit  Mem_Use%  GPU_Util% GPU_Mem%   GPUs     CPUs       Nodes    Queue\n================================================================================================================================================================\n3890***.aqua 01:07:53    48:00:00    02:40:13    295%        2.69       64GB       4.2%      72%       4%         1        8          1        gpu_batch_exec\n3890***.aqua 02:04:52    48:00:00    07:35:42    504%        5.48       64GB       8.6%      47%       12%        1        8          1        gpu_batch_exec\n3905***.aqua 01:35:54    48:00:00    03:57:29    364%        3.32       64GB       5.2%      58%       8%         1        8          1        gpu_batch_exec\n3921***.aqua 20:04:13    24:00:00    21:36:23    160%        11.68      64GB       18.2%     39.7%     28%        1        8          1        gpu_batch_exec\n================================================================================================================================================================\nAVERAGE      06:13:13    42:00:00    -           330.8%      5.79       -          9.1%      54.2%     13.0%      -        -          -        -\n\nJob Statistics:\n--------------\nTotal Jobs: 4\nJobs with GPU: 4\nJobs CPU-only: 0\n\nAverage Resource Efficiency:\n  CPU Usage: 330.8%\n  Memory Usage: 9.1%\n  Walltime Usage: 23.4%\n\nGPU Jobs Metrics (average of 4 GPU jobs):\n  GPU Utilisation: 54.2%\n  GPU Memory Usage: 13.0%\n</code></pre>"},{"location":"pbs-scripts/PBS-Brew-Inspector/#reading-your-tasting-notes","title":"Reading Your Tasting Notes","text":"<p>The real magic happens when you interpret these results. Here's what to look for:</p> <ol> <li>Walltime Efficiency: In the example above, you'll notice jobs using only about 23.4% of the requested walltime. This suggests your jobs could use shorter time requests for better queue priority.</li> <li>Memory Utilisation: With 9.1% average memory usage, you're requesting far more memory than needed. Consider reducing memory requests for faster queue times.</li> <li>GPU Utilisation Patterns: The 54.2% average GPU utilisation indicates reasonable but not optimal GPU use. There might be opportunities to optimise your code to better utilise this expensive resource.</li> <li>CPU Efficiency: A CPU usage of 330.8% on 8-CPU jobs reveals you're effectively using about 4 cores out of 8 - potentially an area for optimisation.</li> </ol>"},{"location":"pbs-scripts/PBS-Brew-Inspector/#pairing-suggestions","title":"Pairing Suggestions","text":"<p><code>pbs_brew_inspector.sh</code> pairs beautifully with:</p> <ul> <li>Guess, Request, Regret: The Art of Walltime: Use these insights to master your walltime estimates</li> <li>More pages coming soon...</li> </ul>"},{"location":"pbs-scripts/PBS-Brew-Inspector/#customisation-notes","title":"Customisation Notes","text":"<p>Like any good recipe, you can customise this tool to your taste:</p> <ul> <li>Modify the output format for specific metrics you care about</li> <li>Add custom calculations for project-specific efficiency metrics</li> <li>Filter for specific job name patterns or time periods</li> <li>Export the data for visualisation in your favourite plotting tool</li> </ul>"},{"location":"pbs-scripts/PBS-Brew-Inspector/#the-brew-inspectors-wisdom","title":"The Brew Inspector's Wisdom","text":"<p>The true artisan understands their ingredients. By regularly inspecting your computational brews, you'll develop an intuition for:</p> <ul> <li>How long similar jobs will take (crucial for walltime estimates)</li> <li>Which resources are your bottlenecks</li> <li>Where you're wasting computational resources</li> <li>How to optimise your code for better efficiency</li> </ul> <p>Remember: analysing your past jobs isn't just about efficiency\u2014it's about becoming fluent in the language of computational resources, and crafting exquisite computational recipes that make the most of your precious cluster time.</p> <p>Happy brewing!</p>"},{"location":"pbs-scripts/PBS-Brew-Inspector/#full-recipe-of-pbs_brew_inspectorsh","title":"Full Recipe of <code>pbs_brew_inspector.sh</code>","text":"<p>Copy the below script and save it as <code>pbs_brew_inspector.sh</code> to your server to use it. Or you can download it from here.</p> pbs_brew_inspector.sh<pre><code>#!/bin/bash\n\n################################################################################\n# Author: Zhipeng He\n# Email: zhipeng.he@hdr.qut.edu.au\n# Last Modified: May 14, 2025\n# Created Date: May 14, 2025\n#\n# This script is used to extract the details of the jobs from the PBS system.\n# It is used to understand the resource usage of the historical jobs.\n#\n# Usage:\n#   ./pbs_job_details.sh [-U username] [-c|-g|-b|-i|-l|-p]\n#\n# Options:\n#   -U username : Specify username (default: current user)\n#   -c : Show all CPU jobs\n#   -g : Show all GPU jobs\n#   -b : Show all batch jobs\n#   -i : Show all interactive jobs\n#   -l : Show large memory jobs\n#   -p : Show persistent jobs\n#\n# Examples:\n#   ./pbs_job_details.sh -c      # Show all CPU jobs\n#   ./pbs_job_details.sh -ci     # Show CPU interactive jobs\n#   ./pbs_job_details.sh -gb     # Show GPU batch jobs\n#   ./pbs_job_details.sh -cl     # Show CPU large memory jobs\n################################################################################\n\n# Default to current user\nUSERNAME=$USER\nSHOW_CPU_BATCH=true\nSHOW_CPU_INTER=true\nSHOW_GPU_BATCH=true\nSHOW_GPU_INTER=true\nSHOW_CPU_BATCH_LARGE=true\nSHOW_CPU_INTER_PERS=true\n\n# Parse command line arguments\nwhile getopts \"U:cbgilp\" opt; do\n    case $opt in\n        U) USERNAME=\"$OPTARG\" ;;\n        c) # CPU jobs\n           SHOW_CPU_BATCH=true\n           SHOW_CPU_INTER=true\n           SHOW_CPU_BATCH_LARGE=true\n           SHOW_CPU_INTER_PERS=true\n           SHOW_GPU_BATCH=false\n           SHOW_GPU_INTER=false\n           ;;\n        g) # GPU jobs\n           SHOW_CPU_BATCH=false\n           SHOW_CPU_INTER=false\n           SHOW_CPU_BATCH_LARGE=false\n           SHOW_CPU_INTER_PERS=false\n           SHOW_GPU_BATCH=true\n           SHOW_GPU_INTER=true\n           ;;\n        b) # Batch jobs\n           SHOW_CPU_BATCH=true\n           SHOW_GPU_BATCH=true\n           SHOW_CPU_INTER=false\n           SHOW_GPU_INTER=false\n           SHOW_CPU_INTER_PERS=false\n           ;;\n        i) # Interactive jobs\n           SHOW_CPU_INTER=true\n           SHOW_GPU_INTER=true\n           SHOW_CPU_BATCH=false\n           SHOW_GPU_BATCH=false\n           SHOW_CPU_BATCH_LARGE=false\n           ;;\n        l) # Large memory jobs\n           SHOW_CPU_BATCH_LARGE=true\n           SHOW_CPU_BATCH=false\n           SHOW_CPU_INTER=false\n           SHOW_GPU_BATCH=false\n           SHOW_GPU_INTER=false\n           SHOW_CPU_INTER_PERS=false\n           ;;\n        p) # Persistent jobs\n           SHOW_CPU_INTER_PERS=true\n           SHOW_CPU_BATCH=false\n           SHOW_CPU_INTER=false\n           SHOW_GPU_BATCH=false\n           SHOW_GPU_INTER=false\n           SHOW_CPU_BATCH_LARGE=false\n           ;;\n        \\?) \n           echo \"Invalid option -$OPTARG\" &gt;&amp;2\n           echo \"Usage: $0 [-U username] [-c|-g|-b|-i|-l|-p]\"\n           echo \"  -U username : Specify username (default: current user)\"\n           echo \"  -c : Show all CPU jobs\"\n           echo \"  -g : Show all GPU jobs\"\n           echo \"  -b : Show all batch jobs\"\n           echo \"  -i : Show all interactive jobs\"\n           echo \"  -l : Show large memory jobs\"\n           echo \"  -p : Show persistent jobs\"\n           echo \"\"\n           echo \"Examples:\"\n           echo \"  $0 -c      # Show all CPU jobs\"\n           echo \"  $0 -ci     # Show CPU interactive jobs\"\n           echo \"  $0 -gb     # Show GPU batch jobs\"\n           echo \"  $0 -cl     # Show CPU large memory jobs\"\n           exit 1\n           ;;\n    esac\ndone\n\n# Function to format time in HH:MM:SS format with leading zeros\nformat_time() {\n    local seconds=$1\n    local hours=$((seconds/3600))\n    local minutes=$((seconds%3600/60))\n    local secs=$((seconds%60))\n    printf \"%02d:%02d:%02d\" $hours $minutes $secs\n}\n\n# Function to convert HH:MM:SS time string to seconds\ntime_to_seconds() {\n    local time_str=$1\n    if [[ -z \"$time_str\" ]]; then\n        echo 0\n        return\n    fi\n    # Use base 10 arithmetic to avoid octal interpretation\n    local hours=$((10#$(echo $time_str | cut -d: -f1)))\n    local minutes=$((10#$(echo $time_str | cut -d: -f2)))\n    local seconds=$((10#$(echo $time_str | cut -d: -f3)))\n    echo $((hours*3600 + minutes*60 + seconds))\n}\n\n# Print table name and header\nprintf \"%s\\n\"\nprintf \"%s\\n\" \"Resource Usage Report -- $USERNAME @ $(date)\"\nprintf \"%s\\n\" \"$(printf '=%.0s' {1..160})\"\n\n# Header for the output table with revised columns\nprintf \"%-13s %-11s %-11s %-11s %-9s %-10s %-10s %-9s %-9s %-10s %-8s %-10s %-8s %-8s\\n\" \\\n\"JobID\" \"Wall_Time\" \"Wall_Limit\" \"CPU_Time\" \"CPU%\" \"Memory\" \"Mem_Limit\" \"Mem_Use%\" \\\n\"GPU_Util%\" \"GPU_Mem%\" \"GPUs\" \"CPUs\" \"Nodes\" \"Queue\"\nprintf \"%s\\n\" \"$(printf '=%.0s' {1..160})\"\n\n# Initialize variables for calculating averages\ntotal_jobs=0\ntotal_gpu_jobs=0\nsum_cpu_percent=0\nsum_mem_use_gb=0\nsum_mem_use_pct=0\nsum_mem_limit_gb=0\nsum_gpu_util=0\nsum_gpu_mem_pct=0\nsum_wall_seconds=0\nsum_wall_limit_seconds=0\nsum_wall_efficiency=0\n\n# Get all held jobs for the user\njobs=$(qstat -H -u $USERNAME | awk '{print $1}' | grep '^[0-9]')\nfor job in $jobs; do\n    output=$(qstat -fx \"$job\")\n    total_jobs=$((total_jobs + 1))\n\n    # Basic job info\n    queue=$(echo \"$output\" | awk '/queue/ {print $3}')\n\n    # Skip if queue doesn't match filter\n    if [[ \"$queue\" == \"cpu_batch_exec\" &amp;&amp; \"$SHOW_CPU_BATCH\" != \"true\" ]] || \\\n       [[ \"$queue\" == \"gpu_batch_exec\" &amp;&amp; \"$SHOW_GPU_BATCH\" != \"true\" ]] || \\\n       [[ \"$queue\" == \"cpu_interactive_exec\" &amp;&amp; \"$SHOW_CPU_INTER\" != \"true\" ]] || \\\n       [[ \"$queue\" == \"gpu_interactive_exec\" &amp;&amp; \"$SHOW_GPU_INTER\" != \"true\" ]] || \\\n       [[ \"$queue\" == \"cpu_batch_large_exec\" &amp;&amp; \"$SHOW_CPU_BATCH_LARGE\" != \"true\" ]] || \\\n       [[ \"$queue\" == \"cpu_interactive_persistent_exec\" &amp;&amp; \"$SHOW_CPU_INTER_PERS\" != \"true\" ]]; then\n        total_jobs=$((total_jobs - 1))\n        continue\n    fi\n\n    # Used resources\n    cpu_time=$(echo \"$output\" | awk '/resources_used.cput/ {print $3}')\n    wall_time=$(echo \"$output\" | awk '/resources_used.walltime/ {print $3}')\n    cpu_percent=$(echo \"$output\" | awk '/resources_used.cpupercent/ {print $3}')\n    [ -z \"$cpu_percent\" ] &amp;&amp; cpu_percent=0\n    sum_cpu_percent=$((sum_cpu_percent + cpu_percent))\n\n    # Allocated resources\n    alloc_wall=$(echo \"$output\" | awk '/Resource_List.walltime/ {print $3}')\n    alloc_cpu=$(echo \"$output\" | awk '/Resource_List.ncpus/ {print $3}')\n    alloc_gpu=$(echo \"$output\" | awk '/Resource_List.ngpus/ {print $3}')\n    [ -z \"$alloc_gpu\" ] &amp;&amp; alloc_gpu=\"0\"\n    node_count=$(echo \"$output\" | awk '/Resource_List.nodect/ {print $3}')\n\n    # Memory usage\n    used_mem_kb=$(echo \"$output\" | awk '/resources_used.mem/ {print $3}' | sed 's/kb//')\n    [ -z \"$used_mem_kb\" ] &amp;&amp; used_mem_kb=0\n    alloc_mem_raw=$(echo \"$output\" | awk '/Resource_List.mem/ {print $3}')\n\n    # Extract numeric value and unit from allocated memory\n    alloc_mem_num=$(echo \"$alloc_mem_raw\" | sed -E 's/([0-9]+)([a-zA-Z]+)/\\1/')\n    alloc_mem_unit=$(echo \"$alloc_mem_raw\" | sed -E 's/([0-9]+)([a-zA-Z]+)/\\2/')\n\n    # Convert to GB if needed\n    case \"${alloc_mem_unit,,}\" in\n        \"gb\") alloc_mem=\"$alloc_mem_num\" ;;\n        \"mb\") alloc_mem=$(awk \"BEGIN {printf \\\"%.2f\\\", $alloc_mem_num / 1024}\") ;;\n        \"kb\") alloc_mem=$(awk \"BEGIN {printf \\\"%.2f\\\", $alloc_mem_num / 1048576}\") ;;\n        *) alloc_mem=\"$alloc_mem_raw\" ;;\n    esac\n\n    used_mem_gb=$(awk \"BEGIN {printf \\\"%.2f\\\", $used_mem_kb / 1048576}\")\n    sum_mem_use_gb=$(awk \"BEGIN {printf \\\"%.2f\\\", $sum_mem_use_gb + $used_mem_gb}\")\n    sum_mem_limit_gb=$(awk \"BEGIN {printf \\\"%.2f\\\", $sum_mem_limit_gb + $alloc_mem}\")\n\n    # Calculate memory usage percentage\n    mem_use_pct=$(awk \"BEGIN {printf \\\"%.1f\\\", ($used_mem_gb / $alloc_mem) * 100}\")\n    sum_mem_use_pct=$(awk \"BEGIN {printf \\\"%.1f\\\", $sum_mem_use_pct + $mem_use_pct}\")\n\n    # GPU metrics - Handle CPU-only jobs\n    if [ \"$alloc_gpu\" != \"0\" ]; then\n        # This is a GPU job\n        total_gpu_jobs=$((total_gpu_jobs + 1))\n\n        gpu_mem=$(echo \"$output\" | awk '/resources_used.gpu_mem_avg/ {print $3}')\n        [ -z \"$gpu_mem\" ] &amp;&amp; gpu_mem=0\n        gpu_mem_pct=\"${gpu_mem}%\"\n        sum_gpu_mem_pct=$(awk \"BEGIN {printf \\\"%.1f\\\", $sum_gpu_mem_pct + $gpu_mem}\")\n\n        gpu_util=$(echo \"$output\" | awk '/resources_used.gpu_percent_avg/ {print $3}')\n        if [[ ! -z \"$gpu_util\" &amp;&amp; \"$gpu_util\" -gt 100 ]]; then\n            # Adjust GPU utilisation percentage if needed (some systems report in thousandths)\n            gpu_util_adj=$(awk \"BEGIN {printf \\\"%.1f\\\", $gpu_util / 1000}\")\n            gpu_util_pct=\"${gpu_util_adj}%\"\n            sum_gpu_util=$(awk \"BEGIN {printf \\\"%.1f\\\", $sum_gpu_util + $gpu_util_adj}\")\n        else\n            [ -z \"$gpu_util\" ] &amp;&amp; gpu_util=0\n            gpu_util_pct=\"${gpu_util}%\"\n            sum_gpu_util=$(awk \"BEGIN {printf \\\"%.1f\\\", $sum_gpu_util + $gpu_util}\")\n        fi\n    else\n        # This is a CPU-only job\n        gpu_util_pct=\"N/A\"\n        gpu_mem_pct=\"N/A\"\n    fi\n\n    # Calculate wall time efficiency\n    wtimesec=$(time_to_seconds \"$wall_time\")\n    wlimitsec=$(time_to_seconds \"$alloc_wall\")\n    sum_wall_seconds=$((sum_wall_seconds + wtimesec))\n    sum_wall_limit_seconds=$((sum_wall_limit_seconds + wlimitsec))\n\n    wall_efficiency=$(awk \"BEGIN {printf \\\"%.1f\\\", ($wtimesec / $wlimitsec) * 100}\")\n    sum_wall_efficiency=$(awk \"BEGIN {printf \\\"%.1f\\\", $sum_wall_efficiency + $wall_efficiency}\")\n\n    # Print row with improved formatting\n    printf \"%-13s %-11s %-11s %-11s %-9s %-10s %-10s %-9s %-9s %-10s %-8s %-10s %-8s %-8s\\n\" \\\n    \"${job}\" \"$wall_time\" \"$alloc_wall\" \"$cpu_time\" \"$cpu_percent%\" \\\n    \"${used_mem_gb}GB\" \"${alloc_mem}GB\" \"${mem_use_pct}%\" \"$gpu_util_pct\" \"$gpu_mem_pct\" \\\n    \"$alloc_gpu\" \"$alloc_cpu\" \"$node_count\" \"$queue\"\ndone\n\n# Calculate averages\nif [ $total_jobs -gt 0 ]; then\n    avg_cpu_percent=$(awk \"BEGIN {printf \\\"%.1f\\\", $sum_cpu_percent / $total_jobs}\")\n    avg_mem_use_gb=$(awk \"BEGIN {printf \\\"%.2f\\\", $sum_mem_use_gb / $total_jobs}\")\n    avg_mem_use_pct=$(awk \"BEGIN {printf \\\"%.1f\\\", $sum_mem_use_pct / $total_jobs}\")\n    avg_mem_limit_gb=$(awk \"BEGIN {printf \\\"%.2f\\\", $sum_mem_limit_gb / $total_jobs}\")\n    avg_wall_seconds=$((sum_wall_seconds / total_jobs))\n    avg_wall_limit_seconds=$((sum_wall_limit_seconds / total_jobs))\n    avg_wall_efficiency=$(awk \"BEGIN {printf \\\"%.1f\\\", $sum_wall_efficiency / $total_jobs}\")\n\n    # Only calculate GPU averages if we have GPU jobs\n    if [ $total_gpu_jobs -gt 0 ]; then\n        avg_gpu_util=$(awk \"BEGIN {printf \\\"%.1f\\\", $sum_gpu_util / $total_gpu_jobs}\")\n        avg_gpu_mem_pct=$(awk \"BEGIN {printf \\\"%.1f\\\", $sum_gpu_mem_pct / $total_gpu_jobs}\")\n        gpu_util_display=\"${avg_gpu_util}%\"\n        gpu_mem_display=\"${avg_gpu_mem_pct}%\"\n    else\n        gpu_util_display=\"N/A\"\n        gpu_mem_display=\"N/A\"\n    fi\n\n    # Format average walltime using the dedicated function\n    avg_wall_time=$(format_time $avg_wall_seconds)\n    avg_wall_limit=$(format_time $avg_wall_limit_seconds)\n\n    # Print separator and averages row\n    printf \"%s\\n\" \"$(printf '=%.0s' {1..160})\"\n    printf \"%-13s %-11s %-11s %-11s %-9s %-10s %-10s %-9s %-9s %-10s %-8s %-10s %-8s %-8s\\n\" \\\n    \"AVERAGE\" \"$avg_wall_time\" \"$avg_wall_limit\" \"-\" \"${avg_cpu_percent}%\" \\\n    \"${avg_mem_use_gb}GB\" \"${avg_mem_limit_gb}GB\" \"${avg_mem_use_pct}%\" \"$gpu_util_display\" \"$gpu_mem_display\" \\\n    \"-\" \"-\" \"-\" \"-\"\nfi\n\n# Job Statistics\necho \"\"\necho \"Job Statistics:\"\necho \"--------------\"\nprintf \"Total Jobs: %d\\n\" \"$total_jobs\"\nprintf \"Jobs with GPU: %d\\n\" \"$total_gpu_jobs\"\nprintf \"Jobs CPU-only: %d\\n\" \"$((total_jobs - total_gpu_jobs))\"\nprintf \"\\nAverage Resource Efficiency:\\n\"\nprintf \"  CPU Usage: %.1f%%\\n\" \"$avg_cpu_percent\"\nprintf \"  Memory Usage: %.1f%% (%.2f GB used / %.2f GB allocated)\\n\" \"$avg_mem_use_pct\" \"$avg_mem_use_gb\" \"$avg_mem_limit_gb\"\nprintf \"  Walltime Usage: %.1f%%\\n\" \"$avg_wall_efficiency\" \n\n# Only show GPU stats if we have GPU jobs\nif [ $total_gpu_jobs -gt 0 ]; then\n    printf \"\\nGPU Jobs Metrics (average of %d GPU jobs):\\n\" \"$total_gpu_jobs\"\n    printf \"  GPU Utilisation: %.1f%%\\n\" \"$avg_gpu_util\"\n    printf \"  GPU Memory Usage: %.1f%%\\n\" \"$avg_gpu_mem_pct\"\nfi\n</code></pre>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/","title":"Surviving without VS Code Remote SSH","text":"<p>\"Or: \"They took away my extension, but not my will to code.\"\"</p> <p>VS Code Remote SSH is banned</p> <p>QUT Aqua banned VS Code Remote SSH extension due to potential high workload on the node. Even you try to connect to Aqua through Remote SSH, it will be disconnected automatically after around 30 seconds. Check this for more details.</p> <p>So... you're trying to develop on QUT Aqua, but the server gods have other plans. Maybe you can't use VS Code Remote SSH. Maybe you're just feeling adventurous. But do not worry \u2014 you can still edit remote files and develop like a champ. Here's how I've kept my sanity while developing on remote HPC systems.</p> Before you start: Recommend to add a shortcut to <code>~/.ssh/config</code> <p>If you are using SSH keys to connect to the HPC, you can add a shortcut to <code>~/.ssh/config</code> to make your life easier. QUT Aqua documentation provides a guide on how to set up SSH keys for passwordless login.</p> <p><pre><code># Add to your ~/.ssh/config\nHost aqua\n    HostName aqua.qut.edu.au\n    User your-username\n    IdentityFile ~/.ssh/id_rsa_aqua # Add your SSH key here\n    ServerAliveInterval 60\n</code></pre> Then, you can connect to the HPC by running <code>ssh aqua</code>. Also, you can use <code>aqua</code> to replace <code>your-username@aqua.qut.edu.au</code> in the following commands.</p>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#1-fake-it-with-ssh-mounted-folders","title":"1. Fake it with SSH-mounted folders","text":""},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#option-a-mount-via-finder-the-cheese-board-approach","title":"Option A: Mount via Finder \u2014 the cheese board approach","text":"<p>Here's a quick guide for macOS users. Please refer to the official documentation for other OS.</p> <ol> <li>Open Finder \u2192 <code>Go</code> \u2192 <code>Connect to Server...</code></li> <li>Enter:</li> </ol> <p><pre><code>smb://hpc-fs/home/\n</code></pre> 3. Mount it, then open the folder in VS Code like it's 1999.</p> <p> Note: You can edit files, but no shell, no Git, and no terminal tantrums. It's like eating cake without the frosting.</p>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#but-is-this-method-elegant","title":"But ... is this method elegant?","text":"<p>You've mounted an SMB share to your Finder. Congratulations! You've just volunteered for the following comedy of errors:</p> <ol> <li>Git? More like \"Get Lost\" - Your carefully crafted version control system now has all the functionality of a chocolate teapot. Want to commit changes? Sorry, Git is too sophisticated for your peasant SMB connection. It's like bringing a quantum physicist to a kindergarten counting class.</li> <li>VS Code's Terminal: The Phantom Feature - That beautiful integrated terminal in VS Code? It now stares at you like a confused puppy. <code>Command not found</code> becomes your new error mantra. It's there... but also not there, like your motivation on Monday mornings.</li> <li>The Mysterious Disconnection - Nothing says \"surprise vacation\" like your SMB connection randomly dropping when you're in the middle of important work. It's like having a co-worker who pulls the fire alarm whenever they're bored.</li> <li>HPC Disruption: The Digital Hostage Situation - Ah, you've put ALL your files on the server! So when the High-Performance Computing cluster decides to have its quarterly existential crisis (or weekly, who's counting?), your work becomes as accessible as your childhood memories. Your options? Make coffee, stare wistfully out the window.</li> <li>The .DS_Store Epidemic: Exclusive for macOS - Ah, macOS and its infamous <code>.DS_Store</code> files! Your Mac scatters these digital breadcrumbs in every folder you visit like an overzealous tourist taking selfies at landmarks. The HPC server, meanwhile, treats them with the same enthusiasm as finding glitter in its keyboard \u2013 \"Thanks for the desktop settings I absolutely didn't ask for and can't use!\" </li> </ol> For macOS users only: How to fix the .DS_Store and ._* files issue <p> </p> <p>Check out The .DS_Store Strikes Back: Finder Edition about why this is a problem and how to solve it (or not).</p>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#option-b-sshfs-mount-through-ssh-wizardry","title":"Option B: SSHFS \u2014 Mount through SSH Wizardry","text":"<p>Mount your HPC home directory directly via SSH, no Finder fluff. It's like having your HPC filesystem in your pocket.</p>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#for-macos-users","title":"For macOS Users:","text":"<pre><code># Install the prerequisites (because your Mac doesn't come with everything, despite what Apple claims)\nbrew install macfuse\nbrew install gromgit/fuse/sshfs-mac\n\n# Mount your HPC home (1)\nmkdir ~/aqua\nsshfs your-username@aqua.qut.edu.au:/home/your-username ~/aqua #(2)\n\n# When you're done pretending these files are local\numount ~/aqua\n# Or if that fails spectacularly (as technology loves to do)\ndiskutil unmount ~/aqua\n</code></pre> <ol> <li>When you're running <code>sshfs</code> first time, you will be asked to go to \"System Preferences\" \u2192 \"Security &amp; Privacy\" \u2192 \"Security\" \u2192 click \"Allow\" for running the app. Then you also need to restart your Mac.</li> <li>You can use <code>aqua</code> to replace <code>your-username@aqua.qut.edu.au</code> if you have added a shortcut to <code>~/.ssh/config</code>.</li> </ol>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#for-linux-users-ubuntu","title":"For Linux Users (Ubuntu):","text":"<pre><code># Install SSHFS (because of course Linux makes you work for everything)\nsudo apt install sshfs\n\n# Mount your HPC home, telling the laws of physics to take a break\nmkdir -p ~/aqua\nsshfs your-username@aqua.qut.edu.au:/home/your-username ~/aqua -o follow_symlinks\n\n# To send these files back to their natural habitat\nfusermount -u ~/aqua\n</code></pre>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#for-windows-users","title":"For Windows Users:","text":"<p>Install WinFSP and SSHFS-Win, because Windows needs two separate things to do what other systems accomplish with one. Then use Windows Explorer (which Microsoft keeps renaming as if that will make us forget its bugs) to map a network drive:</p> <p><pre><code>\\\\sshfs\\your-username@aqua.qut.edu.au\n</code></pre> Then open it in VS Code like you've just performed a miracle:</p> <pre><code>code ~/aqua\n</code></pre> <p> Pro:  - Looks local. Feels local. - Git operations work... until they mysteriously don't</p> <p> Con:  - Feels too local for large files. Might lag. - If the connection drops, your filesystem freezes like it's seen a ghost</p> Performance Tips That Might Help (No Promises) <ul> <li>Use <code>-o cache=yes</code> to create the illusion of performance (side effects may include file synchronization existential crises)</li> <li>Add <code>-o compression=yes</code> to squeeze your data through the internet tubes more efficiently</li> <li>If everything hangs, adjust your <code>ServerAlive</code> settings, which is like giving your connection a gentle nudge every few minutes to check if it's still breathing</li> </ul> Working with Git Over SSHFS: A Tragicomedy <p>When using Git over SSHFS, you're essentially asking Git to perform a synchronized swimming routine while blindfolded. For anything more complex than a simple commit, consider SSH-ing directly into the server and running Git commands there. Your future self will thank you for not testing the limits of your patience.</p> For macOS users only: Still cannot get rid of the .DS_Store and ._* files? <p> </p> <p>Check out The .DS_Store Strikes Back: Finder Edition about why this is a problem and how to solve it (or not).</p>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#2-rsync-scp-and-git-your-old-school-sync-buddies","title":"2. <code>rsync</code>, <code>scp</code> and <code>git</code>: Your old-school sync buddies","text":""},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#option-a-rsync-scp-the-reliable-workhorse","title":"Option A: <code>rsync</code> &amp; <code>scp</code> \u2014 The Reliable Workhorse","text":"<pre><code># Sync your local code to HPC\nrsync -avz ./my-project/ your-username@aqua.qut.edu.au:/home/your-username/projects/\n\n# Sync back from HPC\nrsync -avz your-username@aqua.qut.edu.au:/home/your-username/projects/ ./my-project/\n</code></pre> <p>Or for a quick one-file fling:</p> <pre><code>scp script.py your-username@aqua.qut.edu.au:/home/your-username/projects/\n</code></pre> <p>It's not fancy, but it works \u2014 like duct tape.</p>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#option-b-git-the-version-control-way","title":"Option B: Git \u2014 The Version Control Way","text":"<p>If you are version-controlling your life (as you should), Git is a clean and reliable method.</p> <pre><code># On your local machine\ngit init\ngit add .\ngit commit -m \"Initial commit\"\ngit remote add aqua your-username@aqua.qut.edu.au:/path/to/repo\ngit push aqua main\n\n# On the HPC\ngit clone your-username@aqua.qut.edu.au:/path/to/repo\n</code></pre> <p> Pro: Clean history, branch control, reproducibility</p> <p> Con: Needs initial setup and your SSH keys must behave</p>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#3-the-terminal-only-approach","title":"3. The Terminal-Only Approach","text":"<p>When all else fails, embrace the terminal:</p> <pre><code>ssh your-username@aqua.qut.edu.au\n</code></pre> <p>Then pick your weapon of choice:</p> <ul> <li><code>vim</code> \u2014 For the brave</li> <li><code>nano</code> \u2014 For the sane</li> <li><code>neovim</code> \u2014 For the modern</li> <li><code>emacs</code> \u2014 For the... unique</li> </ul> <p> Bonus: Fast, keyboard-driven, and doesn't require GUI permission forms.</p> <p>Note: I will write another page about how to use <code>neovim</code> and its plugins to replace VS Code as a lightweight editor (with SSH).</p>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#4-the-web-based-approach","title":"4. The Web-Based Approach","text":""},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#option-a-jupyter-notebooks","title":"Option A: Jupyter Notebooks","text":"<p>Install Jupyter Lab in HPC before you start</p> <p>The official Aqua documentation provides a guide on how to install Miniconda in HPC.</p> <pre><code># On the HPC\n# I prefer to use Jupyter Lab instead of Jupyter Notebook\njupyter lab --no-browser --port=8888 # (1)\n\n# On your local machine, forward the port 8888 to your local machine\n# local_port:localhost:remote_port (2)\nssh -N -L 8888:localhost:8888 your-username@aqua.qut.edu.au\n</code></pre> <ol> <li>If port 8888 is already in use, you can try another port, e.g. 8889.</li> <li><code>-N</code> means no command to run on the remote machine. <code>-L</code> means forward the local port to the remote port. Both local and remote ports are 8888 in this case.</li> </ol>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#option-b-vs-code-in-browser","title":"Option B: VS Code in Browser","text":"<p> Warning: This might require a sysadmin's blessing! Fortunately, the server gods haven't locked everything down:</p> <ol> <li>Install <code>code-server</code> on the HPC. <pre><code># On HPC server\n# Install code-server to your home directory\ncurl -fsSL https://code-server.dev/install.sh | sh -s -- --method standalone --prefix=$HOME\n# code-server will be installed to $HOME/bin/code-server\n\n# check if code-server is installed\ncode-server --version\n\n# Start code-server\ncode-server  --bind-addr 127.0.0.1:8080 --disable-telemetry --disable-update-check --auth none\n\n# On your local machine\n# Forward the port 8080 to your local machine\nssh -N -L 8080:127.0.0.1:8080 your-username@aqua.qut.edu.au\n</code></pre></li> <li>Open it in your browser <pre><code># Open the web page in your browser\nhttp://localhost:8080\n</code></pre></li> <li>Marvel as VS Code rises from the ashes \u2014 web-style</li> </ol> Sync VS Code settings to code-server <p>You can import your VS Code settings to code-server by importing the profile from VS Code. Check out this page for more details about how to export and import profiles. However, this's not the perfect solution. Not all VS Code extensions are available for code-server, some extensions are restricted for Microsoft VS Code. Only the extensions that are available for code-server are listed in Open VSX Registry.</p> Run code-server in the background with <code>tmux</code> <p>You can run code-server in the background with <code>tmux</code> to avoid the session being killed after you disconnect from the HPC.</p> <pre><code># Start a new tmux session\ntmux new -s code\n\n# Run code-server in the background\ncode-server --bind-addr 127.0.0.1:8080 --disable-telemetry --disable-update-check --auth none\n\n# Detach from the tmux session: `Ctrl+b`, then `d`\n\n# Reattach to the tmux session\ntmux attach -t code\n\n# Kill the tmux session\ntmux kill-session -t code\n\n# If you forget the session name, you can list all sessions\ntmux ls\n</code></pre> Known issue on Integrated Terminal and Extension Host <p>I found that the terminal and the extension host are not stable when using code-server. The issue seems to revolve around the ptyHost, File Watcher, and Extension Host, and it's being repeatedly killed by SIGTERM.</p> <p> What Is Happening?</p> <pre><code>[12:18:01] ptyHost terminated unexpectedly with code null\n[12:18:01] [File Watcher (universal)] restarting watcher after unexpected error: terminated by itself with code null, signal: SIGTERM (ETERM)\n[12:18:01] [127.0.0.1][d0f383fd][ExtensionHostConnection] &lt;3126357&gt; Extension Host Process exited with code: null, signal: SIGTERM.\n[12:18:02] [127.0.0.1][d0f383fd][ExtensionHostConnection] Unknown reconnection token (seen before).\n[12:18:02] [127.0.0.1][368c67ad][ExtensionHostConnection] New connection established.\n[12:18:02] [127.0.0.1][368c67ad][ExtensionHostConnection] &lt;3132486&gt; Launched Extension Host Process.\n</code></pre> <p>From the logs:</p> <ul> <li> The <code>ptyHost</code> process (responsible for terminal sessions) crashed or was killed \u2014 possibly due to system resource limits or policy.</li> <li> File watcher was forcefully killed (SIGTERM) \u2014 system or job policy likely did this.</li> <li> Extension host was also killed \u2014 same reason, likely tied to HPC rules.</li> <li> code-server tried to reconnect to the crashed extension host but failed.</li> <li> code-server restarted the extension host process automatically.</li> </ul>"},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#tldr-what-works-and-what-requires-sacrifice","title":"TL;DR \u2014 What Works (and What Requires Sacrifice)","text":"Method  Edit in VS Code  Terminal Access  Where Files Live  GUI Needed  Vibe Check SMB (Finder)  Yes, like it's local  Nope, just files  Remote (mounted)  Yes  \"Cheesy but it works\" SSHFS  Yes (mostly)  Not really  Remote (mounted)  Nope  \"Kinda slow, kinda cool\" rsync / Git  Edit local, sync later  Full control  Local (then synced)  Nope  \"Old school, solid\" Terminal Editors  No GUI, no problem  Born in the terminal  Remote (SSH only)  Nope  \"For shell warriors\" Jupyter  Yes, via browser  If allowed  Remote (Jupyter workspace)  Yes  \"Science with style\" code-server  Yes, but web-based  Unstable  Remote (in browser)  Yes  \"Feels like cheating\""},{"location":"remote-dev/Surviving-without-VS-Code-Remote-SSH/#final-words","title":"Final Words","text":"<p>Remote development on HPC doesn't have to be a pain. Pick your poison, set up your workflow, and remember: the best development environment is the one that doesn't make you want to throw your computer out the window.</p> <p>Happy coding, and may your HPC connections be stable! \ud83d\ude80</p>"},{"location":"remote-dev/The-DS_Store-Strikes-Back/","title":"The .DS_Store Strikes Back: Finder Edition","text":"<p>A long time ago, on a remote server far, far away...</p>"},{"location":"remote-dev/The-DS_Store-Strikes-Back/#episode-v-the-ds_store-strikes-back","title":"EPISODE V: THE .DS_STORE STRIKES BACK","text":"<p>The Dark Side of macOS</p> <p>Imperial .DS_Store files have driven Rebel developers from their remote server folders. These hidden files spread like the Dark Side across every folder you visit.</p> <ul> <li> <p>Darth <code>.DS_Store</code>: \"Your lack of <code>defaults write</code> is disturbing. My hidden files will spread across every folder you visit.\"</p> </li> <li> <p>Luke: \"But I've tried <code>.gitignore</code>! It has no power here on remote connections!\"</p> </li> <li> <p>Yoda: \"Use the Terminal, Luke. Or the sacred command to disable .DS_Store on network volumes.\"</p> </li> <li> <p>Han: \"I've been running from these hidden files for ten years. Not a remote server is safe in the galaxy!\"</p> </li> </ul>"},{"location":"remote-dev/The-DS_Store-Strikes-Back/#the-solution-clean-up-the-dark-side","title":"The Solution: Clean Up the Dark Side","text":"<ol> <li> <p>Remove Existing .DS_Store Files <pre><code># Clean up all .DS_Store files\nfind . -name \".DS_Store\" -delete\n</code></pre></p> </li> <li> <p>Prevent Future .DS_Store Creation <pre><code># Disable .DS_Store on network volumes\ndefaults write com.apple.desktopservices DSDontWriteNetworkStores -bool TRUE\n\n# Restart Finder to apply changes\nkillall Finder\n</code></pre></p> </li> </ol>"},{"location":"remote-dev/The-DS_Store-Strikes-Back/#episode-vi-the-return-of-the-metadata-_","title":"EPISODE VI: THE RETURN OF THE METADATA (._*)","text":"<p>\"The ._* files are back, and they're more annoying than ever.\"</p> <p>The Hidden Menace</p> <p>When you copy files to a remote server, macOS creates mysterious <code>._*</code> files. They're like the Ewoks of the file system - small, seemingly harmless, but they can cause big problems.</p> <ul> <li> <p>Darth Metadata: \"Your files are not complete without my metadata. I will follow them everywhere.\"</p> </li> <li> <p>Luke: \"But these <code>._*</code> files are causing issues with my Python scripts!\"</p> </li> <li> <p>Yoda: \"Hidden they are, but dangerous they can be. Clean them you must.\"</p> </li> </ul>"},{"location":"remote-dev/The-DS_Store-Strikes-Back/#the-solution-defeat-the-metadata-menace","title":"The Solution: Defeat the Metadata Menace","text":"<ol> <li> <p>Remove Existing Metadata Files <pre><code># Remove all ._ files\nfind . -name \"._*\" -delete\n\n# Or clean both .DS_Store and ._ files\nfind . -type f -name \"._*\" -o -name \".DS_Store\" -delete\n</code></pre></p> </li> <li> <p>Understanding the ._* Files - The Unstoppable Force</p> <p>On macOS, preventing the creation of <code>._*</code> files (AppleDouble metadata) entirely is not officially supported\u2014especially on non-HFS+ or non-APFS volumes.</p> <p>Why ._* files are created: macOS uses ._* AppleDouble files to store:</p> <pre><code>- Resource forks\n- Extended attributes (e.g., custom icons, tags)\n- Finder metadata\n\nThese are automatically created when copying files to filesystems that don't support extended attributes, such as:\n- SMB shares (Linux Samba servers)\n- FAT, exFAT, NTFS drives\n- Some WebDAV volumes\n</code></pre> </li> <li> <p>Best Available Solutions </p> <p>Just kidding, there are no best available solutions for this problem. That's why I said mount the remote server as a local drive by Finder is not an elegant solution.</p> </li> <li> <p>For Git Users</p> <p>Add the following to your .gitignore file: <pre><code># Add to your .gitignore (won't prevent creation, but prevents tracking)\necho \"._*\\n.DS_Store\" &gt;&gt; .gitignore\n</code></pre></p> </li> </ol>"},{"location":"remote-dev/The-DS_Store-Strikes-Back/#final-words","title":"Final Words","text":"<p>\"The Force is strong with clean file systems.\"</p> <p>May your remote development be free of metadata files, and may the Force be with you! \ud83d\ude80 </p>"},{"location":"scheduler/Know-Your-Nodes/","title":"Know Your Nodes: A Field Guide to HPC Resources","text":"<p>Last Updated</p> <p>This guide was last reviewed on May 13, 2025. Node availability and specifications might change over time.</p>"},{"location":"scheduler/Know-Your-Nodes/#whats-on-the-menu","title":"What's on the Menu?","text":"<p>So you want to run your code, but what hardware should you order? Welcome to the HPC buffet \u2014 where some dishes are fast but small, others are huge but slow, and the good stuff always seems to be reserved for someone else. This field guide will help you identify which computational beasts are available and how to lure them into running your jobs with minimum fuss.</p>"},{"location":"scheduler/The-Art-of-Walltime/","title":"Guess, Request, Regret: The Art of Walltime","text":""},{"location":"scheduler/The-Art-of-Walltime/#the-great-walltime-dilemma","title":"The Great Walltime Dilemma","text":"<p>So, you're staring at the PBS script prompt, cursor blinking accusingly at <code>#PBS -l walltime=??:??:??</code>, and you're playing that familiar game: \"How long will this actually take?\" Welcome to The Art of Walltime \u2014 where every estimate is a guess, every request is a prayer, and every job termination is potential regret.</p> <p>This guide is essentially a survival manual that:</p> <ul> <li>Helps you interpret your historical job data (like reading tea leaves, but with actual numbers).</li> <li>Shows you how to make walltime decisions that won't keep you up at night.</li> <li>Teaches you to balance between \"too short and doomed to fail\" and \"so long you'll die of old age in the queue.\"</li> <li>Respects the sacred 48-hour limit (except for the mythical persistent queue).</li> </ul> <p>Result: Jobs that actually finish, queue priority that doesn't make you weep, and the sweet, sweet feeling of resource efficiency.</p>"},{"location":"scheduler/The-Art-of-Walltime/#the-walltime-calculation-ritual","title":"The Walltime Calculation Ritual","text":""},{"location":"scheduler/The-Art-of-Walltime/#1-check-your-job-history-know-thyself","title":"1. Check Your Job History (Know Thyself)","text":"<p>See <code>pbs_brew_inspector.sh</code> recipe from PBS Brew Inspector: Tasting Notes from Your Job History.</p> <p>Before you guess, see what your past jobs tell you. Use the <code>pbs_brew_inspector.sh</code> script to get wisdom from the past:</p> <pre><code>./pbs_brew_inspector.sh -g  # For GPU jobs\n./pbs_brew_inspector.sh -c  # For CPU jobs\n</code></pre> <p>What to look for:</p> <ul> <li>True Runtime vs Requested Walltime - How much of your requested time are you actually using?</li> <li>Walltime Usage % - If this is consistently low, you're being wasteful!</li> <li>Job patterns - Are similar jobs taking consistent time?</li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#2-the-golden-ratio-the-2x-rule","title":"2. The Golden Ratio: The 2x Rule","text":"<p>Take your best guess at how long your job will run. Now double it. This isn't pessimism; it's realism with a safety cushion.</p> <p>Why this works:</p> <ul> <li>Accounts for unexpected dataset quirks</li> <li>Covers random slowdowns from shared resources</li> <li>Gives you time to notice if something's gone horribly wrong</li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#3-queue-sensitivity-analysis-know-your-environment","title":"3. Queue Sensitivity Analysis (Know Your Environment)","text":""},{"location":"scheduler/The-Art-of-Walltime/#queue-walltime-limits","title":"Queue Walltime Limits","text":"<p>See detailed queue limits in QUT Aqua HPC Documentation.</p> <p>QUT Aqua HPC system has specific queue limits you should know intimately:</p> <ul> <li> <p>12:00:00 (12 hours)</p> <ul> <li>CPU Interactive Jobs (<code>cpu_inter_exec</code>)</li> <li>GPU Interactive Jobs (<code>gpu_inter_exec</code>)</li> </ul> </li> <li> <p>48:00:00 (2 days)</p> <ul> <li>CPU Batch Jobs (<code>cpu_batch_exec</code>)</li> <li>GPU Batch Jobs (<code>gpu_batch_exec</code>)</li> <li>CPU Batch Large Memory Jobs (<code>cpu_batch_exlm</code>)</li> </ul> </li> <li> <p>368:00:00 (15 days)</p> <ul> <li>Interactive Persistent Jobs (<code>cpu_inter_pers</code>)</li> </ul> </li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#critical-distinction","title":"Critical distinction","text":"<ul> <li>Batch jobs release resources as soon as they finish (even if they finish early).</li> <li>Interactive jobs hold their resources for the entire walltime (even if your task is done).</li> </ul> <p>The longer your walltime request, the longer you'll wait in the queue. It's not just policy; it's physics. Or politics. Or both.</p>"},{"location":"scheduler/The-Art-of-Walltime/#practical-walltime-science","title":"Practical Walltime Science","text":""},{"location":"scheduler/The-Art-of-Walltime/#the-walltime-estimation-formula","title":"The Walltime Estimation Formula","text":"<pre><code>Requested_Walltime = (Previous_Runtime \u00d7 Scaling_Factor) + Safety_Margin\n</code></pre> <p>Where:</p> <ul> <li>Previous_Runtime: From similar jobs or early testing</li> <li>Scaling_Factor: Based on dataset size changes (1.5x data \u2248 1.5x time)</li> <li>Safety_Margin: 1 hour for short jobs, 4+ hours for multi-day runs</li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#scaling-rules-of-thumb","title":"Scaling Rules of Thumb","text":"<ul> <li>Linear algorithms: Batch size \u00d7 2 = Time \u00d7 2</li> <li>Complex ML training: Batch size \u00d7 2 \u2260 Time \u00d7 2 (usually less)</li> <li>Multi-node jobs: Adding nodes rarely gives perfect speedup</li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#warning-signs-youre-doing-it-wrong","title":"Warning Signs You're Doing It Wrong","text":""},{"location":"scheduler/The-Art-of-Walltime/#walltime-sins-and-their-punishments","title":"Walltime Sins and Their Punishments","text":"<ul> <li> <p>The Miniaturist: Requesting 1 hour for a 50-epoch training job. Punishment: Endless cycle of failed jobs and lost progress.</p> </li> <li> <p>The Hoarder: Requesting 7 days for a 4-hour job. Punishment: Your job ages like fine wine in the queue while your deadline approaches like a freight train.</p> </li> <li> <p>The Queue Mismatched: Putting a 24-hour job in a 12-hour interactive queue. Punishment: Guaranteed failure halfway through, with bonus frustration.</p> </li> <li> <p>The Copy-Paster: Using the same walltime for every job without thought. Punishment: Developing a reputation with the HPC admins, who will tell stories about you at their holiday parties.</p> </li> <li> <p>The Optimist: \"It'll definitely be faster this time!\" Punishment: Explaining to your supervisor why you have no results for the meeting.</p> </li> <li> <p>The Resource Hog: Running minor tasks in batch queues with max resources. Punishment: Everyone in the Uni quietly resenting you.</p> </li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#troubleshooting-your-walltime-woes","title":"Troubleshooting Your Walltime Woes","text":"<p>Even the best walltime artists occasionally create masterpieces of miscalculation. Here's how to recover:</p>"},{"location":"scheduler/The-Art-of-Walltime/#when-jobs-die-too-young","title":"When Jobs Die Too Young","text":"<p>If your jobs keep hitting walltime limits:</p> <ul> <li>Emergency Checkpoint: Implement regular checkpoints in your code</li> <li>Divide and Conquer: Split work into smaller chunks with job dependencies</li> <li>Post-mortem Analysis: Review the last few output lines before termination</li> <li>Run Time Estimation: Add progress tracking with estimated completion time</li> <li>Queue Migration: Consider moving from interactive (12h limit) to batch (48h limit)</li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#when-youre-stuck-in-queue-purgatory","title":"When You're Stuck in Queue Purgatory","text":"<p>If your jobs never seem to start:</p> <ul> <li>Queue Status Check: Use <code>qstat -q</code> to see all queue loads</li> <li>Right-sizing: Consider if you can use a different queue with different limits</li> <li>Time vs Resources Trade: Sometimes less RAM/GPUs but longer walltime is the better choice</li> <li>Memory Reality Check: Are you requesting more than the queue's memory range allows?</li> <li>Batch vs Interactive: Remember batch jobs release resources early; interactive jobs don't</li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#the-interactive-job-conundrum","title":"The Interactive Job Conundrum","text":"<p>When using interactive queues, remember:</p> <ul> <li>They hold resources for the full walltime even if your code finishes early</li> <li>They have much shorter walltime limits (12h vs 48h)</li> <li>They typically have lower resource limits (e.g., 2 GPUs vs 8 GPUs)</li> <li>Use <code>cpu_inter_pers</code> only when you really need 7+ days of runtime</li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#walltime-recipes-for-common-scenarios","title":"Walltime Recipes for Common Scenarios","text":""},{"location":"scheduler/The-Art-of-Walltime/#recipe-the-quick-test-run","title":"Recipe: The Quick Test Run","text":"<pre><code>#PBS -l walltime=01:00:00\n#PBS -q cpu_inter_exec  # or gpu_inter_exec if you need GPUs\n</code></pre> <p>Best for:</p> <ul> <li>Checking if your code runs at all</li> <li>Testing on small subsets of data</li> <li>Debugging startup issues</li> <li>When you'll be actively monitoring</li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#recipe-the-standard-training-run","title":"Recipe: The Standard Training Run","text":"<pre><code>#PBS -l walltime=24:00:00\n#PBS -q gpu_batch_exec  # For ML workloads\n</code></pre> <p>Best for:</p> <ul> <li>Most ML model training</li> <li>Medium-sized data processing</li> <li>Jobs with established completion patterns</li> <li>When you need those precious GPUs</li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#recipe-the-i-have-no-idea-special","title":"Recipe: The \"I Have No Idea\" Special","text":"<pre><code>#PBS -l walltime=04:00:00\n#PBS -q cpu_batch_exec\n</code></pre> <p>Best for:</p> <ul> <li>First runs of new code</li> <li>Exploratory analysis</li> <li>When you truly can't estimate (but don't want to clog the queue)</li> <li>When you know it needs more than interactive time</li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#recipe-the-weekend-warrior","title":"Recipe: The Weekend Warrior","text":"<pre><code>#PBS -l walltime=48:00:00  # The max for most queues\n#PBS -q gpu_batch_exec  # Or cpu_batch_exec\n</code></pre> <p>Best for:</p> <ul> <li>Jobs submitted Friday that you want done by Monday</li> <li>Large-scale computations you've already tested</li> <li>When you won't be available to restart failures</li> <li>Hitting the maximum walltime and hoping for the best</li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#recipe-the-pipeline-master","title":"Recipe: The Pipeline Master","text":"<pre><code>#PBS -l walltime=168:00:00  # 7 days\n#PBS -q cpu_inter_pers\n</code></pre> <p>Best for:</p> <ul> <li>Workflow pipelines that need to persist</li> <li>Long-running services that coordinate other jobs</li> <li>Jobs where you truly need more than 48 hours</li> <li>When you're willing to sacrifice cores for time (only 1 core is needed)</li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#additional-tips-from-the-walltime-whisperers","title":"Additional Tips From the Walltime Whisperers","text":"<ul> <li> <p>Progress Bars are Your Friend: Add <code>tqdm</code> or similar progress tracking to your scripts - they help you make better estimates next time.</p> </li> <li> <p>Walltime Poetry: Different queues, different rules. Learn the poetry of your specific HPC system.</p> </li> <li> <p>The Batch Advantage: Batch jobs release resources as soon as they finish. If your job might finish early, always use batch over interactive.</p> </li> <li> <p>Two-Phase Approach: Run a small version of your job first in an interactive queue to establish a baseline, then scale your walltime request accordingly for the batch queue.</p> </li> <li> <p>Checkpoint Everything: Your future self will thank you when that 47-hour job crashes at hour 46.</p> </li> <li> <p>The \"Kill Switch\": Always have a way to gracefully terminate your job early if you realise you've made a horrible walltime mistake. Use <code>qhold &lt;job_id&gt;</code> to pause your job and <code>qdel &lt;job_id&gt;</code> to cancel it.</p> </li> <li> <p>Analyse Your Usage: Using <code>pbs_brew_inspector.sh</code>, track your average walltime efficiency. Aim for 75-85% usage of requested time.</p> </li> </ul>"},{"location":"scheduler/The-Art-of-Walltime/#the-walltime-warriors-creed","title":"The Walltime Warrior's Creed","text":"<ol> <li>I shall not request more time than I need.</li> <li>I shall not trust my first estimate.</li> <li>I shall checkpoint regularly and defensively.</li> <li>I shall learn from each job's runtime.</li> <li>I shall remember interactive jobs hold resources until the bitter end.</li> <li>I shall respect the 48-hour limit of most queues.</li> <li>I shall curse quietly when my perfect estimate is still wrong.</li> </ol>"},{"location":"scheduler/The-Art-of-Walltime/#when-all-else-fails-the-emergency-protocols","title":"When All Else Fails: The Emergency Protocols","text":"<ul> <li> <p>The HPC Whisperer: Make friends with your HPC admin. They know secrets of the queues you can only dream of.</p> </li> <li> <p>The Queue Switcher: If your job won't fit in a 48-hour window, break it up or adapt it for the persistent queue.</p> </li> <li> <p>The Late-Night Submission: Some say submitting at 2 AM magically improves queue position. We can neither confirm nor deny.</p> </li> <li> <p>The \"Please Don't Die\" Ritual: This involves staring anxiously at your job's progress while muttering \"just finish already\" under your breath.</p> </li> <li> <p>The 47:30 Panic Attack: When you realize your 48-hour job might actually need 48:30, and you start frantically implementing checkpointing.</p> </li> </ul> <p>Remember: Walltime isn't just a number \u2013 it's a relationship between you, your code, your data, the specific queue limits, and the cruel mistress of computational fate.</p>"},{"location":"scheduler/The-Art-of-Walltime/#coming-soon","title":"Coming Soon...","text":"<ul> <li>A guide to interpreting cryptic error messages when your job dies with 5 seconds of walltime remaining.</li> <li>The psychological impact of watching your perfectly estimated job finish with exactly 00:00:01 remaining.</li> <li>Advanced negotiations with the queue scheduler: bargaining, pleading, and acceptance.</li> <li>Walltime support group: sharing stories of that time you asked for 48 hours and it took 48 hours and 3 minutes.</li> </ul> <p>Remember, the perfect walltime doesn't exist. But the perfect walltime estimate does.</p>"}]}